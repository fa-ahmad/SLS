{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44519fb",
   "metadata": {},
   "source": [
    "# Structured Learning Session \n",
    "## Project 1: Build a Clinical Support Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754edc4b",
   "metadata": {},
   "source": [
    "## Step 0\n",
    "### Get to know the environment\n",
    "- Run BASH commands from this notebook\n",
    "- Go up and down the directory tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ddd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27e8c9c9",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "### Download the Kaggle Chest X-ray (Pneumonia) Dataset\n",
    "- Create a Kaggle account\n",
    "- Go to the [account](https://www.kaggle.com/udacityinc/account) page.\n",
    "- Create and download an API token to your personal system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd35fc",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "### Install the Kaggle API \\[[Reference](https://www.kaggle.com/docs/api#installation)\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a3962",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8248cd33",
   "metadata": {},
   "source": [
    "## Step 3 \n",
    "### Set up Kaggle API token \\[[Reference](https://www.kaggle.com/docs/api#authentication)\\]\n",
    "- Move the Kaggle API token to a directory named `.kaggle` inside the home directory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f518e2",
   "metadata": {},
   "source": [
    "Check the directory we are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bcc03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7688ed6c",
   "metadata": {},
   "source": [
    "Create the hidden directory `.kaggle` inside the home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd920e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /home/ec2-user/.kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a6bee",
   "metadata": {},
   "source": [
    "Check that the direcotry has been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189960c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -al /home/ec2-user/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c3d6fa",
   "metadata": {},
   "source": [
    "From the GUI upload the kaggle.json API token file to the current direcotry \n",
    "then move it to the newly created directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv kaggle.json /home/ec2-user/.kaggle/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ceb2a0",
   "metadata": {},
   "source": [
    "\\[OPTIONAL\\]Restrict access rights to the API token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07cc364",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 600 /home/ec2-user/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a736d",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "### Set up the dataset in Sagemaker\n",
    "- Create a directory named `data`\n",
    "- Download the [pneumonia dataset](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) using the Kaggle API\n",
    "- Unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85509fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./data\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia --path ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd447d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip  -q ./data/chest-xray-pneumonia.zip -d ./data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192723c2",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "### Explore a few data samples\n",
    "- Look at the direcotry structure of the dataset\n",
    "- Pay attention to the naming scheme of the image files in the NORMAL and PNEUMONIA sub-directories \n",
    "- Is the training dataset balanced?\n",
    "- Plot a few images from the two categories\n",
    "- Is there a pronounced difference between normal and pneumonia X-rays?\n",
    "- How large are the images? Is the image size fixed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s ../S2/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a306a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './data/chest_xray/'\n",
    "train_data_dir = 'train'\n",
    "test_data_dir = 'test'\n",
    "val_data_dir = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eece2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {data_root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3731778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {data_root+train_data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10caa4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l {data_root+train_data_dir+\"/PNEUMONIA\"} | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l {data_root+train_data_dir+\"/NORMAL\"} | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3304bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = './data/chest_xray/train/NORMAL/IM-0122-0001.jpeg'\n",
    "sample_image = Image.open(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cdeffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c03e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_image,cmap='gray')\n",
    "plt.title('h: '+str(sample_image.height)+' w: '+str(sample_image.width))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61609d22",
   "metadata": {},
   "source": [
    "## Step 6\n",
    "### Understand the problem\n",
    "- What are some distinctive features used by clinicians? \\[[Reference](https://www.radiologyinfo.org/en/info/pneumonia#:~:text=Chest%20x%2Dray%3A%20An%20x,infiltrates\\)%20that%20identify%20an%20infection.)\\]\n",
    "- Are clinicians always sure about the condition? \\[[Reference](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/overview)\\]\n",
    "- What is a good performance baseline that we should try to achieve or beat? \\[[Reference](https://www.mdedge.com/familymedicine/article/60101/infectious-diseases/how-accurate-clinical-diagnosis-pneumonia#:~:text=Sensitivity%20of%20clinical%20diagnosis%20ranged%20from%2047%25%20to%2069%25%2C%20and%20specificity%20from%2058%25%20to%2075%25.)\\], \\[[Reference](https://arxiv.org/pdf/1711.05225.pdf)\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d74fa4c",
   "metadata": {},
   "source": [
    "- How's pneumonia detected? \n",
    ">Chest x-ray: An x-ray exam will allow your doctor to see your lungs, heart and blood vessels to help determine if you have pneumonia. When interpreting the x-ray, the radiologist will look for white spots in the lungs (called infiltrates) that identify an infection. \n",
    "[Source](https://www.radiologyinfo.org/en/info/pneumonia#:~:text=Chest%20x%2Dray%3A%20An%20x,infiltrates\\)%20that%20identify%20an%20infection.)\n",
    "\n",
    "- Are clinicians always sure about the condition?\n",
    ">While common, accurately diagnosing pneumonia is a tall order. It requires review of a chest radiograph (CXR) by highly trained specialists and confirmation through clinical history, vital signs and laboratory exams. Pneumonia usually manifests as an area or areas of increased opacity [3] on CXR. However, the diagnosis of pneumonia on CXR is complicated because of a number of other conditions in the lungs such as fluid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes. Outside of the lungs, fluid in the pleural space (pleural effusion) also appears as increased opacity on CXR. When available, comparison of CXRs of the patient taken at different time points and correlation with clinical symptoms and history are helpful in making the diagnosis.\n",
    "[Source](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/overview)\n",
    "   \n",
    "   \n",
    "- What is a good performance baseline that we should try to achieve or beat?\n",
    ">Sensitivity of clinical diagnosis ranged from 47% to 69%, and specificity from 58% to 75%\n",
    "[Source](https://www.mdedge.com/familymedicine/article/60101/infectious-diseases/how-accurate-clinical-diagnosis-pneumonia#:~:text=Sensitivity%20of%20clinical%20diagnosis%20ranged%20from%2047%25%20to%2069%25%2C%20and%20specificity%20from%2058%25%20to%2075%25.). F1 scores vary from 0.33 to 0.44\n",
    "[Source](https://arxiv.org/pdf/1711.05225.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad6a38a",
   "metadata": {},
   "source": [
    "## Step 7\n",
    "### Select an ML approach \n",
    "- What kind of algorithm/model is best suited?\n",
    "- Do we have adequate data?\n",
    "    - How can we augment the data?\n",
    "    - Which augmentations will not make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba738cee",
   "metadata": {},
   "source": [
    "- What kind of algorithm/model is best suited? \n",
    "```\n",
    "The number of samples in the training set is really small for training a deep learning model from the grounds up. A pretrained model can be used as a feature extractor and even fine-tuned further.\n",
    "```\n",
    "[Source](https://arxiv.org/abs/1711.05225)\n",
    "\n",
    "- How can we augment the data?\n",
    "```\n",
    "Rotation and brightness and contrast adjustments make sense. One can also apply horizontal flipping.\n",
    "```\n",
    "[Source](https://arxiv.org/abs/1711.05225)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6644aff2",
   "metadata": {},
   "source": [
    "## Step 8\n",
    "### Create Pytorch dataloaders for training, validation and testing\n",
    "- Decide data tranformations\n",
    "- Create Pytorch datasets from the folder structure\n",
    "- Create dataloaders from the corresponding datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba72acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Why Imagenet?: https://discuss.pytorch.org/t/how-to-preprocess-input-for-pre-trained-networks/683/2\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f17d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All normalizations below done using the image net mean and std. deviation\n",
    "## as described here: https://discuss.pytorch.org/t/how-to-preprocess-input-for-pre-trained-networks/683/2 \n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN,\n",
    "                         IMAGENET_STD)\n",
    "])\n",
    "\n",
    "test_transforms =  transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN,\n",
    "                         IMAGENET_STD)\n",
    "])\n",
    "\n",
    "\n",
    "val_transforms =  transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN,\n",
    "                         IMAGENET_STD)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c05511",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(os.path.join(data_root,train_data_dir),transform=train_transforms)\n",
    "test_dataset = ImageFolder(os.path.join(data_root,test_data_dir), transform=test_transforms)\n",
    "val_dataset = ImageFolder(os.path.join(data_root,val_data_dir), transform=val_transforms)\n",
    "print(train_dataset, test_dataset, val_dataset, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7086a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b360f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SZ = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SZ, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SZ, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SZ, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e23d32",
   "metadata": {},
   "source": [
    "## Step 9\n",
    "### Sanity test the data \n",
    "- Plot a few random data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = {v:k for k,v in train_dataset.class_to_idx.items()}\n",
    "idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963655e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(x):\n",
    "    return x * IMAGENET_STD+IMAGENET_MEAN\n",
    "\n",
    "def tensor_to_img(t):\n",
    "    return t.numpy().transpose(1,2,0)\n",
    "\n",
    "def tensor_to_label(t):\n",
    "    return idx_to_class[int(t.numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924449d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_X, sample_y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18613bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169371d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e5f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(denormalize(tensor_to_img(sample_X[3]))); plt.title(\"class:\"+str(tensor_to_label(sample_y[3])));plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7aaf3c",
   "metadata": {},
   "source": [
    "## Step 10\n",
    "### Shop around for a model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282e70c2",
   "metadata": {},
   "source": [
    "- Instantiate a pretrained Resnet18 model \\[[Reference](https://pytorch.org/vision/stable/models.html)\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12398bc",
   "metadata": {},
   "source": [
    "- Understand the model's architecture and functioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f695498",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee17bb13",
   "metadata": {},
   "source": [
    "> The model has three disconnected segments, each can be accessed using `model.segmentname`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61513145",
   "metadata": {},
   "source": [
    "- Freeze the model \\[[Reference](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor)\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e4f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a250fa3",
   "metadata": {},
   "source": [
    "- Decapitate the model and use a different classifier dense layers 256, 64, 1 \\[[Reference](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor)\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Linear, ReLU, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = Sequential(\n",
    "    Linear(in_features=512, out_features=256, bias=True),\n",
    "    ReLU(),\n",
    "    Dropout(p=0.5, inplace=True),\n",
    "    Linear(in_features=256, out_features=64, bias=True),\n",
    "    ReLU(),\n",
    "    Dropout(p=0.5, inplace=True),\n",
    "    Linear(in_features=64, out_features=1, bias=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f808451",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891c99b2",
   "metadata": {},
   "source": [
    "## Step 11\n",
    "### Pre-heat the oven\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea01c7",
   "metadata": {},
   "source": [
    "- Define a loss function appropriate for binary classification based on the following criteria\n",
    "    - Appropriate for a classification problem \\[[Reference](https://pytorch.org/docs/stable/nn.html#loss-functions)\\]\n",
    "    - Compatible with the size of the output layer (Single neuron vs. 1-neuron per class) \\[[Reference](https://stats.stackexchange.com/q/207049/348089)\\]\n",
    "    - Compatible with the type of the output (logit, softmax, sigmoid) \\[[Reference](https://stackoverflow.com/a/43577384/17203040)\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13466e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e2c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971d451",
   "metadata": {},
   "source": [
    "- Instantiate an optimizer \\[[Optimizer](https://pytorch.org/docs/stable/optim.html)\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d455f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbde76a",
   "metadata": {},
   "source": [
    "## Step 12\n",
    "### Implement training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e5d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c882f012",
   "metadata": {},
   "source": [
    "- Implement the `train()` function that trains the model for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c54f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "    \n",
    "    ## Set the model in training mode and copy the model to the device\n",
    "    model.train()\n",
    "    model = model.to(device)   \n",
    "    \n",
    "    for batch_X, batch_y in tqdm(loader):\n",
    "        \n",
    "        ## Move the batch to the device\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        ## Clear the optimizer's accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## Pass the data through the model and collect the logits\n",
    "        logits = model(batch_X)\n",
    "        \n",
    "        ## Calculate the loss and backpropagate errors\n",
    "        loss = loss_fn(logits.squeeze(), batch_y.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        ## Run the optimizer to update the parameters based on backpropagated errors\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27666400",
   "metadata": {},
   "source": [
    "- Implement the `evaluate()` function to compute the loss, and any other metrics we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, loss_fn, device, pos_label, neg_label):\n",
    "    \n",
    "    ## Set the model in evaluation\n",
    "    model.eval()\n",
    "    model = model.to(device)   \n",
    "    \n",
    "    total_loss = 0\n",
    "    total_TP = total_FN = total_TN = total_FP = 0\n",
    "    for batch_X, batch_y in tqdm(loader):\n",
    "        \n",
    "        ## Move the batch to the device\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        ## Pass the data through the model and collect the logits\n",
    "        logits = model(batch_X)\n",
    "        \n",
    "        ## Calculate the loss \n",
    "        loss = loss_fn(logits.squeeze(), batch_y.float())\n",
    "\n",
    "        ## Accumulate the loss\n",
    "        total_loss += loss.detach().cpu().numpy()\n",
    "        \n",
    "        ## Compute predicted labels\n",
    "        probs = torch.sigmoid(logits.squeeze())\n",
    "        preds = probs > 0.5\n",
    "        \n",
    "        ## Compute batch TP, FP, FN, TN\n",
    "        total_TP += ((preds == pos_label) & (batch_y == pos_label)).sum().item()\n",
    "        total_FN += ((preds == neg_label) & (batch_y == pos_label)).sum().item()\n",
    "        total_TN += ((preds == neg_label) & (batch_y == neg_label)).sum().item()\n",
    "        total_FP += ((preds == pos_label) & (batch_y == neg_label)).sum().item()\n",
    "    \n",
    "    sensitivity = total_TP / (total_TP+total_FN)\n",
    "    specificity = total_TN / (total_TN+total_FP)\n",
    "    accuracy = (total_TP+total_TN) / (total_TP+total_FN+total_TN+total_FP)\n",
    "    \n",
    "    \n",
    "        \n",
    "    return {'loss':total_loss/len(loader), 'sensitivity':sensitivity, 'specificity':specificity, 'accuracy':accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a94f52d",
   "metadata": {},
   "source": [
    "- Select device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df40f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de24b3aa",
   "metadata": {},
   "source": [
    "- **Sanity test:** Train and evaluate the model on a tiny subset(~100) of the training set (train/eval on the same subset) for a few epochs \\[[Reference](https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset)\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088bd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_dataset = Subset(train_dataset, np.random.randint(0,len(train_dataset)-1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5832c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_loader = DataLoader(sample_train_dataset, BATCH_SZ, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for e in range(1,EPOCHS+1):\n",
    "    train(model, sample_train_loader,optimizer,loss_fn, device)\n",
    "    val_loss = evaluate(model, sample_train_loader,loss_fn, device, train_dataset.class_to_idx['PNEUMONIA'], train_dataset.class_to_idx['NORMAL'])\n",
    "    print(f'Epoch: {e}, loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278bee9",
   "metadata": {},
   "source": [
    "## Step 13\n",
    "### Set up training on a separate instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f470906",
   "metadata": {},
   "source": [
    "- Create a new Sagemaker session and get execution role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf52af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ee2c7f",
   "metadata": {},
   "source": [
    "- Get the default S3 bucket \\[[Reference](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-ex-bucket.html)\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f854e6b",
   "metadata": {},
   "source": [
    "- Move our data directory to the path `sagemaker/pneumonia` on the S3 bucket.\n",
    "  **This operation is time consuming. Jump ahead to next steps after executing your code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76ce90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'sagemaker/pneumonia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f794037",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = sagemaker_session.upload_data(path=data_root, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0f939",
   "metadata": {},
   "source": [
    "- Use the AWS CLI to check if the data has been transfered. \\[[Reference](https://aws.amazon.com/cli/)\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c344a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://{bucket+'/'+prefix+'/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa7813d",
   "metadata": {},
   "source": [
    "- Create a directory named `train` and create the file `train.py` within it. This will be the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd72c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir train; touch train/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea543c5e",
   "metadata": {},
   "source": [
    "- Write the body of the taining script adapting from the code [here](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#prepare-a-pytorch-training-script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9865b7cf",
   "metadata": {},
   "source": [
    "- Copy code to create the train and validation datasets from this notebook into the training script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822bd1cd",
   "metadata": {},
   "source": [
    "- Copy code to set up the model, the loss function and the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef0ff3",
   "metadata": {},
   "source": [
    "- Adapt code to train the model on the **entire training set** and evaluate training and validation losses every epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d4b2be",
   "metadata": {},
   "source": [
    "- Add code to save the model at the end of the training \\[[Reference](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#save-the-model)\\].\n",
    "Saving is necessary if we want to make predictions using the remote model and the Sagemaker API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe092e14",
   "metadata": {},
   "source": [
    "- Invoke the cell below that executes the train/train.py script with approrpriate arguments to check if the code runs without errors. **You may want to interrupt the execution since the full training is too slow**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export SM_MODEL_DIR='./model' SM_CHANNEL_TRAIN=s3://{bucket+'/'+prefix+'/'};python train/train.py --epochs 1 --batch-size 32 --model-dir ./model --data-dir {data_root}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d5138",
   "metadata": {},
   "source": [
    "- Create a PyTorch estimator using the Sagemaker API \\[[Reference](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#create-an-estimator)\\]. Use `ml.p2.xlarge` instance type and pass hyperparameter as needed. Keep the number of epochs small (1-2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f44c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_estimator = PyTorch(entry_point= 'train.py',\n",
    "                            source_dir='train',\n",
    "                            instance_type='ml.p2.xlarge',\n",
    "                            instance_count=1,\n",
    "                            framework_version=torch.__version__,\n",
    "                            py_version='py3',\n",
    "                            role=role,\n",
    "                            hyperparameters = {'epochs': 1, 'batch-size': 32, 'use-cuda':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_estimator.fit({'train': f\"s3://{bucket+'/'+prefix+'/'}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e315b10",
   "metadata": {},
   "source": [
    "## Step 14\n",
    "### Deploying the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a51ac6f",
   "metadata": {},
   "source": [
    "- To deploy a model, Sagemaker expects to have a function named `model_fn()` in the script \\[[Reference](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#load-a-model)\\]. This function should load and return the model saved by the training process. **Implement `model_fn()` in our code.**\n",
    "    - Recreate the model architecture.\n",
    "    - Load the model's parameters saved by the training process\n",
    "    - Set the model in evaluation mode\n",
    "    - Copy the model over to the right device\n",
    "    - Return the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f45ae3",
   "metadata": {},
   "source": [
    "- Re-run the Pytorch estimator creation and `estimator.fit()` cells above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2aa17c",
   "metadata": {},
   "source": [
    "- Create a predictor by calling `deploy()` on the estimator. Use an `ml.m4.xlarge` instance for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10cab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy my estimator to a SageMaker Endpoint and get a Predictor\n",
    "predictor = pytorch_estimator.deploy(instance_type='ml.t2.medium',\n",
    "                                     initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe19616",
   "metadata": {},
   "source": [
    "- Load any sample image from the test dataset using the test loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c76429",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef9562b",
   "metadata": {},
   "source": [
    "- Display the image and its class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57966d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(denormalize(tensor_to_img(test_X[1]))); plt.title(\"class:\"+str(tensor_to_label(test_y[1])));plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d9879d",
   "metadata": {},
   "source": [
    "- Convert the image data from Pytorch tensor to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bcc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = test_X[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3414c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c26f9",
   "metadata": {},
   "source": [
    "- Send the numpy array to our predictor. Since the predictor is remote, Sagemaker takes care of serializing and deserealizing the data and the model's prediction\\[[Reference](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#serve-a-pytorch-model)\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predictor.predict(img_data.reshape([1,*img_data.shape]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b078a94f",
   "metadata": {},
   "source": [
    "- The output of the predictor will be a logit, pass it through a sigmoid to get a probability in the range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cbcaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 1/(1+np.exp(-output))\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a64a5d4",
   "metadata": {},
   "source": [
    "- Threshold the probability at 0.5 to get a prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750be6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = int(prob > 0.5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa791a2",
   "metadata": {},
   "source": [
    "- Convert the prediction to a label using `idx_to_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eac8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class[pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed538e",
   "metadata": {},
   "source": [
    "- To serve models Sagemakers spins up a server. When we call `predictor.predict(data)`, the data is serialized and sent to this server. After we are done making predictions, we need to shutdown the server to save cost. **Delete the endpoint created by the predictor.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71550b3",
   "metadata": {},
   "source": [
    "## Step 15\n",
    "### Accessing the deployed model without the use of the predictor object "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52558071",
   "metadata": {},
   "source": [
    "- Print the deployed model's endpoint identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b517ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.endpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf749024",
   "metadata": {},
   "source": [
    "- (Re-)Create a predictor object using the endpoint of the deployed model\n",
    "    - Use the sagemaker.predictor.Predictor class\n",
    "    - Use `sagemaker.serializers.NumpySerializer`, `sagemaker.deserializers.NumpyDeserializer()` as the serializer and deserializer. (why's this needed?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e158756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_endpoint = Predictor(predictor.endpoint, \n",
    "                               serializer=sagemaker.serializers.NumpySerializer(),\n",
    "                               deserializer=sagemaker.deserializers.NumpyDeserializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf06178f",
   "metadata": {},
   "source": [
    "- Create image payload by inserting an empty `batch` dimension to the numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d17bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_payload = img_data.reshape([1,*img_data.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac96783",
   "metadata": {},
   "source": [
    "- Invoke the `predict()` method of the new predictor and capture its response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_response = predictor_endpoint.predict(data=img_payload)\n",
    "print(inference_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b25af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 1/(1+np.exp(-int(inference_response)))\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = int(prob > 0.5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f6cb73",
   "metadata": {},
   "source": [
    "- Delete the predictor(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b33ecd",
   "metadata": {},
   "source": [
    "## Step 16\n",
    "### Invoke the endpoint from outside the notebook (from a Lambda function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea4925",
   "metadata": {},
   "source": [
    "- Create a Lambda function and assign it an IAM role that allows unrestricted access to Sagemaker (Why is this needed?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a8328",
   "metadata": {},
   "source": [
    "- Use the endpoint approach to create a predictor object call its `predict` method on a sample image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb949f",
   "metadata": {},
   "source": [
    "## Step 17\n",
    "### Speedup Hacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7791d7",
   "metadata": {},
   "source": [
    "- Resize images only once\n",
    "- Generate bottleneck features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
